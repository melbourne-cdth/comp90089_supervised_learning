{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg7TfjhhqwEi"
   },
   "source": [
    "# Machine Learning Applications for Health (COMP90089)\n",
    "### Supervised Learning using MIMIC-IV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtlAPZR0qwEl"
   },
   "source": [
    "> ## Goal: Predict the mortality risk for Sepsis Cohort\n",
    "* We are going to play with two types of **Supervised** Algorithms: **Naive-Bayes and KNN.**\n",
    "* The Python lybrary will be sklearn. To check their **documentation**, please click [here](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IxCNUK_qwEm"
   },
   "source": [
    "Set up the **environment**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0TmtjohqwEm"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Access data using Google BigQuery.\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYQovpHfMTP7"
   },
   "outputs": [],
   "source": [
    "# authenticate\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeLkBccujW7N"
   },
   "source": [
    "* Next: Change the **project_id** variable (in the first line only) with the corresponding Project ID name of your Big Query project for MIMIC-IV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLtANN_eMWBx"
   },
   "outputs": [],
   "source": [
    "# Set up environment variables\n",
    "project_id = 'CHANGE-ME'\n",
    "if project_id == 'CHANGE-ME':\n",
    "  raise ValueError('You must change project_id to your GCP project.')\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
    "\n",
    "# Read data from BigQuery into pandas dataframes.\n",
    "def run_query(query, project_id=project_id):\n",
    "  return pd.io.gbq.read_gbq(\n",
    "      query,\n",
    "      project_id=project_id,\n",
    "      dialect='standard')\n",
    "\n",
    "# set the dataset\n",
    "dataset = 'mimiciv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJII3uxZqwEo"
   },
   "source": [
    "## Data\n",
    "\n",
    "We'll use a cohort derived from MIMIC-IV.\n",
    "\n",
    "* The query bellow is searching for the data in the **BigQuery Platform**.\n",
    "* We are retrieving patients with **Sepsis**: A life-threatening complication caused by the body's response to an infection. When your immune system goes into **overdrive in response to an infection**, sepsis may develop as a result\n",
    "* Further, we will join the Date of Death information, the age and gender from patients table.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77HrSabnqwEo"
   },
   "outputs": [],
   "source": [
    "##We are retrieving patients using sepsis3 Table and joining it to patients Table.\n",
    "\n",
    "df = run_query(\"\"\"\n",
    "SELECT sep.subject_id,sep.sofa_score,sep.respiration,sep.coagulation,sep.liver,sep.cardiovascular,sep.cns,sep.renal,pt.dod,pt.anchor_age,pt.gender\n",
    "FROM `physionet-data.mimiciv_derived.sepsis3` as sep\n",
    "INNER JOIN `physionet-data.mimiciv_hosp.patients` as pt\n",
    "ON sep.subject_id = pt.subject_id\n",
    "ORDER BY subject_id\n",
    "\"\"\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN2vGpboPd9I"
   },
   "source": [
    "> ## How is the data set? Analyse it!\n",
    "\n",
    "\n",
    "* Analyse and prepare the Data: missing values, numerical or categorical features. What needs to be changed, replaced or even removed?\n",
    "\n",
    "* What is the target column to be predicted by the classifier?\n",
    "  * **Date of death** (dod column) is our target variable. What is the type of data? Is it suitable for machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlxSfa2YPRUY"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) ##This is only to show all columns when printing a DataFrame\n",
    "\n",
    "#Create a copy of the dataframe to work with\n",
    "sepsis_df = df.copy()\n",
    "\n",
    "#Check missing values \n",
    "print(sepsis_df.isnull().sum(),\"\\n\\n\")\n",
    "\n",
    "#Check the type of data for each column. Notice that 'gender' is categorical (object) and 'dod' is time series.\n",
    "print(sepsis_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZDLJTJtWwHx"
   },
   "source": [
    "### Transforming Categorical into Numbers:\n",
    "* get_dummies: Columns with dtype = (object or category) will be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7x6zJzNWt9x"
   },
   "outputs": [],
   "source": [
    "#Replace Date of Death times with binary (0 or 1)\n",
    "sepsis_df.loc[sepsis_df['dod'].notna(),'dod'] = int(1)\n",
    "sepsis_df.loc[sepsis_df['dod'].isnull(),'dod'] = int(0)\n",
    "sepsis_df['dod'] = sepsis_df['dod'].astype(int)\n",
    "\n",
    "#Transform Gender column from Categorical Data to Binary:\n",
    "##WRITE THE CODE HERE\n",
    "\n",
    "#Concatenate both Data frames:\n",
    "##WRITE THE CODE HERE\n",
    "final_sepsis  = \n",
    "\n",
    "#Final Data set to work with: remove 'subject_id','gender' columns.\n",
    "##WRITE THE CODE HERE\n",
    "final_sepsis  =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_9ak_2ExZGk"
   },
   "outputs": [],
   "source": [
    "#Check the final dtype of each column. Are they properly defined now? \n",
    "print(final_sepsis.info(),\"\\n\\n\")\n",
    "\n",
    "#How is the data distributed? Outliers?\n",
    "##WRITE THE CODE HERE\n",
    "\n",
    "## How balanced is the data?\n",
    "##WRITE THE CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4qnOjwg0R0c"
   },
   "source": [
    "## Split the data set into random train and test subsets\n",
    "\n",
    "* We will use the function **train_test_split** from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to randomly split the data, creating the training and testing subsets.\n",
    "\n",
    "* Split the Dependent variables (or Features) from the Independent Variable (Target - what will be predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK1hj-Yu0SjS"
   },
   "outputs": [],
   "source": [
    "## Split the Dependent variables (or Features) from the Independent Variable (Target - what will be predicted)\n",
    "\n",
    "# Target of classification\n",
    "y = final_sepsis['dod']\n",
    "# Features\n",
    "X = final_sepsis.drop(['dod'], axis=1)\n",
    "\n",
    "## Random suffle and create the subsets for training and testing\n",
    "# We can keep 80% of the data to Train the model and the remaining 20% for Testing.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(\"Check the subsets size: X_train:{}, y_train:{}, X_test:{}, y_test:{}. \\n\\n\".format(X_train.shape,y_train.shape,X_test.shape,y_test.shape))\n",
    "\n",
    "print(\"X_train matches with y_train\")\n",
    "print(\"X_test matches with y_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caEjpTc0qwEq"
   },
   "source": [
    "> ## Naive-Bayes Classifier:\n",
    "\n",
    "*Naive Bayes* methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable.\n",
    "\n",
    "* **GaussianNB** implements the Gaussian Naive Bayes algorithm for classification.\n",
    "\n",
    "* **Parameter**: \n",
    "  * **var_smoothing** (float, default=1e-9). It's the portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvkxNFGFqwEq"
   },
   "outputs": [],
   "source": [
    "#Training the Naive-Bayes:\n",
    "classifier_NB = GaussianNB()\n",
    "model_NB = classifier_NB.fit(X_train,y_train)\n",
    "\n",
    "#Predict the classifier response for the Test dataset:\n",
    "predictions_NB = model_NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97gmGsaiqwEs"
   },
   "source": [
    "### Evaluate the model, how good is it? \n",
    "\n",
    "* The **sklearn.metrics** module implements several loss, score, and utility functions to measure classification performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmGlwakb1xW1"
   },
   "outputs": [],
   "source": [
    "#Accuracy classification score\n",
    "acc_NB = float(round(metrics.accuracy_score(y_test, predictions_NB),3))\n",
    "\n",
    "#Compute the balanced accuracy.\n",
    "bacc_NB = float(round(metrics.balanced_accuracy_score(y_test, predictions_NB),3))\n",
    "\n",
    "#Compute the Matthews correlation coefficient (MCC)\n",
    "mcc_NB = float(round(metrics.matthews_corrcoef(y_test, predictions_NB),3))\n",
    "\n",
    "#Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "f1_NB = float(round(metrics.f1_score(y_test, predictions_NB),3))\n",
    "\n",
    "#Save results as a DataFrame:\n",
    "results = {'Accuracy' : [acc_NB], 'Balanced Accuracy' : [bacc_NB], 'MCC' : [mcc_NB], 'F1-Score' : [f1_NB]}\n",
    "nb_results = pd.DataFrame.from_dict(data = results, orient='columns')\n",
    "print(nb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65U6MylMPCn_"
   },
   "source": [
    "## Cross-Validation: a roubust approach for evaluating the model performance\n",
    "\n",
    "* In the basic approach, called k-fold CV, the training set is split into k smaller sets.\n",
    "* **cross_val_score**: Evaluate a score by cross-validation. See short doc [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) and long [here](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "\n",
    "* Let's try again with the Naive-Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTxnmSPxKnqk"
   },
   "outputs": [],
   "source": [
    "##Let's try again with the Naive-Bayes and full data set:\n",
    "\n",
    "#Number of Folds to split the data:\n",
    "folds = 5\n",
    "\n",
    "#Call the function of cross-validation passing the parameters:\n",
    "scores = cross_val_score(estimator = classifier_NB, X = X_train, y = y_train, cv = folds, scoring = 'f1') #can replace scoring string by = ‘f1’, ‘accuracy’, 'balanced_accuracy'.\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVr_jwjZU4cl"
   },
   "outputs": [],
   "source": [
    "##Check the performance results per fold:\n",
    "\n",
    "cv_metrics_NB = pd.DataFrame(data = scores, columns = ['F1-Score_CV'], index = ['cv_1','cv_2','cv_3','cv_4','cv_5'])\n",
    "print(cv_metrics_NB)\n",
    "print(\"The mean F1 Score over the 5 folds is: \",round(scores.mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIUSJhQvRvek"
   },
   "source": [
    "### Improving Naive-Bayes:\n",
    "\n",
    "* **GridSearchCV**: Exhaustive search over specified parameter values for an estimator. Check the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "* Example of Tutorial: [here](https://medium.com/analytics-vidhya/how-to-improve-naive-bayes-9fa698e14cba)\n",
    "\n",
    "Remember that **var_smoothing** is a stability calculation to widen (or smooth) the curve and therefore account for more samples that are further away from the distribution mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liq7gg5XRu_e"
   },
   "outputs": [],
   "source": [
    "##Check different values for the parameter var_smoothing \n",
    "\n",
    "#In this case, np.logspace returns numbers spaced evenly on a log scale, starts from 0, ends at -9, and generates 100 samples.\n",
    "param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "# Search for the best var_smooting parameter value using the Training Data set under a 5 fold cross-validation approach\n",
    "nbModel_grid = GridSearchCV(estimator = GaussianNB(), param_grid = param_grid_nb, verbose = 1, cv = 5)\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameter value: \n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDaA8t0EgB3y"
   },
   "source": [
    "* Evaluate the Performance again for the tuned Naive-Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMi2HcN4Se9O"
   },
   "outputs": [],
   "source": [
    "## Evaluate the Performance of the new Naive-Bayes model with the Testing set\n",
    "\n",
    "#Predict the testing set\n",
    "y_pred = nbModel_grid.predict(X_test)\n",
    "\n",
    "#Accuracy classification score\n",
    "acc_NB_new = float(round(metrics.accuracy_score(y_test, y_pred),3))\n",
    "\n",
    "#Compute the balanced accuracy.\n",
    "bacc_NB_new = float(round(metrics.balanced_accuracy_score(y_test, y_pred),3))\n",
    "\n",
    "#Compute the Matthews correlation coefficient (MCC)\n",
    "mcc_NB_new = float(round(metrics.matthews_corrcoef(y_test, y_pred),3))\n",
    "\n",
    "#Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "f1_NB_new = float(round(metrics.f1_score(y_test, y_pred),3))\n",
    "\n",
    "#Show results as a DataFrame:\n",
    "results_new = {'Accuracy' : [acc_NB_new], 'Balanced Accuracy' : [bacc_NB_new], 'MCC' : [mcc_NB_new], 'F1-Score' : [f1_NB_new]}\n",
    "nb_results_new = pd.DataFrame.from_dict(data = results_new, orient='columns')\n",
    "print(nb_results_new)\n",
    "\n",
    "print(\"\\n\\n Previous performance results BEFORE parameter optimisation: \\n\",nb_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VHzCMw0BvWH"
   },
   "source": [
    "### **Bonus**: K-Nearest Neighbors Classifier\n",
    "\n",
    "*Neighbors-based* classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.\n",
    "\n",
    "* **KNeighborsClassifier** implements learning based on the  nearest neighbors of each query point, where  is an integer value specified by the user.\n",
    "\n",
    "* **Parameter**: \n",
    "  * **n_neighborsint**: Number of neighbours (default = 5)\n",
    "  * Choosing the optimal value of n_neighborsint is critical, so we fit and test the model for different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvmgB_g2Bu_O"
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "## How to choose the best number of neighbours? Let's create a range and see it!\n",
    "\n",
    "k_values = range(1,20)\n",
    "KNN_scores = []\n",
    "\n",
    "for n in k_values:\n",
    "  classifier_KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "  model_KNN = classifier_KNN.fit(X_train,y_train)\n",
    "  \n",
    "  #Predict the classifier's responses for the Test dataset\n",
    "  predictions_KNN = model_KNN.predict(X_test)\n",
    "\n",
    "  #Evaluate using MCC:\n",
    "  KNN_scores.append(float(round(metrics.matthews_corrcoef(y_test, predictions_KNN),3)))\n",
    "\n",
    "print(KNN_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNrfBGR3hi9O"
   },
   "source": [
    "* ### Visualise how the MCC metric varies with different values of Neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "pygGqD0nhfO-",
    "outputId": "b3c60f63-8734-4ab2-f418-91fada1d5933"
   },
   "outputs": [],
   "source": [
    "##Visualise how the MCC metric varies with different values of Neighbors:\n",
    "plt.plot(k_values, KNN_scores)\n",
    "plt.xlabel(\"Number of Neighbours\")\n",
    "plt.ylabel(\"MCC Performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHS_iKb3h6Vm"
   },
   "outputs": [],
   "source": [
    "#Get the number of neighbours of the maximum MCC score:\n",
    "print(KNN_scores.index(max(KNN_scores))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h285jrsCiCM_"
   },
   "outputs": [],
   "source": [
    "classifier_KNN_new = KNeighborsClassifier(n_neighbors = 19)\n",
    "model_KNN_new = classifier_KNN_new.fit(X_train,y_train)\n",
    "  \n",
    "#Predict the classifier's responses for the Test dataset\n",
    "predictions_KNN_new = model_KNN_new.predict(X_test)\n",
    "\n",
    "\n",
    "## Evaluate the different Performance metrics for the new KNN model with the Testing set\n",
    "\n",
    "#Accuracy classification score\n",
    "acc_KNN_new = float(round(metrics.accuracy_score(y_test, predictions_KNN_new),3))\n",
    "\n",
    "#Compute the balanced accuracy.\n",
    "bacc_KNN_new = float(round(metrics.balanced_accuracy_score(y_test, predictions_KNN_new),3))\n",
    "\n",
    "#Compute the Matthews correlation coefficient (MCC)\n",
    "mcc_KNN_new = float(round(metrics.matthews_corrcoef(y_test, predictions_KNN_new),3))\n",
    "\n",
    "#Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "f1_KNN_new = float(round(metrics.f1_score(y_test, predictions_KNN_new),3))\n",
    "\n",
    "#Show results as a DataFrame:\n",
    "results_KNN_new = {'Accuracy' : [acc_KNN_new], 'Balanced Accuracy' : [bacc_KNN_new], 'MCC' : [mcc_KNN_new], 'F1-Score' : [f1_KNN_new]}\n",
    "KNN_results_new = pd.DataFrame.from_dict(data = results_KNN_new, orient='columns')\n",
    "print(KNN_results_new)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
